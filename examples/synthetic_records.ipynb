{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic data\n",
    "\n",
    "This notebook walks through training a probabilistic, generative RNN model<br>\n",
    "on a rental scooter location dataset, and then generating a synthetic<br>\n",
    "dataset with greater privacy guarantees. \n",
    "\n",
    "For both training and generating data, we can use the ``config.py`` module and<br>\n",
    "create a ``LocalConfig`` instance that contains all the attributes that we need<br>\n",
    "for both activities.\n",
    "\n",
    "In the below example, we will create a config that can work on a CPU. Performing<br> \n",
    "operations on a GPU is recommended with more complex settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab support\n",
    "# Note: Click \"Runtime->Change Runtime Type\" set Hardware Accelerator to \"GPU\"\n",
    "#\n",
    "#!pip install gretel-synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gretel_synthetics.config import LocalConfig\n",
    "\n",
    "# Create a config that we can use for both training and generating, with CPU-friendly settings\n",
    "# The default values for ``max_chars`` and ``epochs`` are better suited for GPUs\n",
    "\n",
    "config = LocalConfig(\n",
    "    max_chars=100000,  # friendly towards CPUs\n",
    "    epochs=5,  # friendly towards CPUs\n",
    "    vocab_size=500, # tokenizer model vocabulary size\n",
    "    character_coverage=1.0, # tokenizer model character coverage percent\n",
    "    gen_chars=0, # the maximum number of characters possible per-generated line of text\n",
    "    gen_lines=100, # the number of generated text lines\n",
    "    rnn_units=256, # dimensionality of LSTM output space\n",
    "    batch_size=64, # batch size\n",
    "    buffer_size=1000, # buffer size to shuffle the dataset\n",
    "    dropout_rate=0.2, # fraction of the inputs to drop\n",
    "    dp=True, # let's use differential privacy\n",
    "    dp_learning_rate=0.015, # learning rate\n",
    "    dp_noise_multiplier=1.1, # control how much noise is added to gradients\n",
    "    dp_l2_norm_clip=1.0, # bound optimizer's sensitivity to individual training points\n",
    "    dp_microbatches=256, # split batches into minibatches for parallelism\n",
    "    checkpoint_dir=os.path.join(os.getcwd(), 'checkpoints'),\n",
    "    input_data=\"https://gretel-public-website.s3-us-west-2.amazonaws.com/datasets/uber_scooter_rides_1day.csv\" # filepath or S3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "# The training function only requires our config as a single arg\n",
    "from gretel_synthetics.train import train_rnn\n",
    "\n",
    "train_rnn(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate some text!\n",
    "#\n",
    "# The ``generate_text`` funtion is a generator that will return\n",
    "# a line of predicted text based on the ``gen_lines`` setting in your\n",
    "# config.\n",
    "#\n",
    "# There is no limit on the line length as with proper training, your model\n",
    "# should learn where newlines generally occur. However, if you want to\n",
    "# specify a maximum char len for each line, you may set the ``gen_chars``\n",
    "# attribute in your config object\n",
    "from gretel_synthetics.generate import generate_text\n",
    "\n",
    "# Optionally, when generating text, you can provide a callable that takes the \n",
    "# generated line as a single arg. If this function raises any errors, the \n",
    "# line will fail validation and will not be returned.  The exception message\n",
    "# will be provided as a ``explain`` field in the resulting dict that gets\n",
    "# created by ``generate_text``\n",
    "def validate_record(line):\n",
    "    rec = line.split(\", \")\n",
    "    if len(rec) == 6:\n",
    "        float(rec[5])\n",
    "        float(rec[4])\n",
    "        float(rec[3])\n",
    "        float(rec[2])\n",
    "        int(rec[0])\n",
    "    else:\n",
    "        raise Exception('record not 6 parts')\n",
    "        \n",
    "for line in generate_text(config, line_validator=validate_record):\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
